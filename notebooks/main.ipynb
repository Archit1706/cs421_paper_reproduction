{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[43mpreprocess_hatewic_individual\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHateWiC_IndividualAnnos.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/processed_HateWiC_IndividualAnnos.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m, in \u001b[0;36mpreprocess_hatewic_individual\u001b[1;34m(input_path, output_path)\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Only keep annotator labels that are usable\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot decide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Normalize labels (subjective task): map to binary\u001b[39;00m\n\u001b[0;32m     10\u001b[0m label_map \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot hateful\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeakly hateful\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrongly hateful\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def preprocess_hatewic_individual(input_path: str, output_path: str):\n",
    "    df = pd.read_csv(input_path, sep=\";\")\n",
    "\n",
    "    # Only keep annotator labels that are usable\n",
    "    df = df[df['label'] != 'Cannot decide']\n",
    "\n",
    "    # Normalize labels (subjective task): map to binary\n",
    "    label_map = {\n",
    "        'Not hateful': 0,\n",
    "        'Weakly hateful': 1,\n",
    "        'Strongly hateful': 1\n",
    "    }\n",
    "    df['encoded_label'] = df['label'].map(label_map)\n",
    "\n",
    "    # Use unique annotation ID as ID\n",
    "    df['id'] = df['annotation_id']\n",
    "\n",
    "    # Save processed version\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved cleaned data to {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_hatewic_individual(\n",
    "        input_path='HateWiC_IndividualAnnos.csv',\n",
    "        output_path='data/processed_HateWiC_IndividualAnnos.csv'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>annotator_age</th>\n",
       "      <th>annotator_gender</th>\n",
       "      <th>annotator_ethnicity</th>\n",
       "      <th>annotator_profile_description</th>\n",
       "      <th>example_id</th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>pos</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>wiktionary_definition</th>\n",
       "      <th>agree_with_majority_binary</th>\n",
       "      <th>id</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-0</td>\n",
       "      <td>annotator_14</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Reader is 22, Male and Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>annotator_31</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 22, Male and White</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>1-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2</td>\n",
       "      <td>annotator_47</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Reader is 22, Female and Other</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>1-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-1</td>\n",
       "      <td>annotator_18</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Reader is 32, Female and Black</td>\n",
       "      <td>2</td>\n",
       "      <td>They look at those massive tummies and ample a...</td>\n",
       "      <td>Aberzombie</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An unthinking conformist who wears fashions fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>2-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2-2</td>\n",
       "      <td>annotator_34</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 35, Female and White</td>\n",
       "      <td>2</td>\n",
       "      <td>They look at those massive tummies and ample a...</td>\n",
       "      <td>Aberzombie</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An unthinking conformist who wears fashions fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>2-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12437</th>\n",
       "      <td>4670-1</td>\n",
       "      <td>annotator_59</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 24, Female and White</td>\n",
       "      <td>4670</td>\n",
       "      <td>Fuck me, there's actually more ziggers on tele...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4670-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12438</th>\n",
       "      <td>4670-2</td>\n",
       "      <td>annotator_65</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 21, Male and White</td>\n",
       "      <td>4670</td>\n",
       "      <td>Fuck me, there's actually more ziggers on tele...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4670-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12439</th>\n",
       "      <td>4671-0</td>\n",
       "      <td>annotator_8</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 25, Male and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12440</th>\n",
       "      <td>4671-1</td>\n",
       "      <td>annotator_24</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 24, Male and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12441</th>\n",
       "      <td>4671-2</td>\n",
       "      <td>annotator_66</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 32, Female and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11902 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation_id  annotator_id  annotation_label  binary_label  \\\n",
       "0               1-0  annotator_14  Strongly hateful           1.0   \n",
       "1               1-1  annotator_31    Weakly hateful           1.0   \n",
       "2               1-2  annotator_47       Not hateful           0.0   \n",
       "4               2-1  annotator_18    Weakly hateful           1.0   \n",
       "5               2-2  annotator_34       Not hateful           0.0   \n",
       "...             ...           ...               ...           ...   \n",
       "12437        4670-1  annotator_59    Weakly hateful           1.0   \n",
       "12438        4670-2  annotator_65  Strongly hateful           1.0   \n",
       "12439        4671-0   annotator_8  Strongly hateful           1.0   \n",
       "12440        4671-1  annotator_24    Weakly hateful           1.0   \n",
       "12441        4671-2  annotator_66    Weakly hateful           1.0   \n",
       "\n",
       "       annotator_age annotator_gender annotator_ethnicity  \\\n",
       "0                 22             Male               Mixed   \n",
       "1                 22             Male               White   \n",
       "2                 22           Female               Other   \n",
       "4                 32           Female               Black   \n",
       "5                 35           Female               White   \n",
       "...              ...              ...                 ...   \n",
       "12437             24           Female               White   \n",
       "12438             21             Male               White   \n",
       "12439             25             Male               White   \n",
       "12440             24             Male               White   \n",
       "12441             32           Female               White   \n",
       "\n",
       "        annotator_profile_description  example_id  \\\n",
       "0        Reader is 22, Male and Mixed           1   \n",
       "1        Reader is 22, Male and White           1   \n",
       "2      Reader is 22, Female and Other           1   \n",
       "4      Reader is 32, Female and Black           2   \n",
       "5      Reader is 35, Female and White           2   \n",
       "...                               ...         ...   \n",
       "12437  Reader is 24, Female and White        4670   \n",
       "12438    Reader is 21, Male and White        4670   \n",
       "12439    Reader is 25, Male and White        4671   \n",
       "12440    Reader is 24, Male and White        4671   \n",
       "12441  Reader is 32, Female and White        4671   \n",
       "\n",
       "                                                 example          term   pos  \\\n",
       "0                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "1                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "2                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "4      They look at those massive tummies and ample a...    Aberzombie  noun   \n",
       "5      They look at those massive tummies and ample a...    Aberzombie  noun   \n",
       "...                                                  ...           ...   ...   \n",
       "12437  Fuck me, there's actually more ziggers on tele...        zigger  noun   \n",
       "12438  Fuck me, there's actually more ziggers on tele...        zigger  noun   \n",
       "12439  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "12440  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "12441  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "\n",
       "       sense_id                              wiktionary_definition  \\\n",
       "0             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "1             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "2             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "4             1  An unthinking conformist who wears fashions fr...   \n",
       "5             1  An unthinking conformist who wears fashions fr...   \n",
       "...         ...                                                ...   \n",
       "12437         2           A Russian who supports Kremlin doctrine.   \n",
       "12438         2           A Russian who supports Kremlin doctrine.   \n",
       "12439         2           A Russian who supports Kremlin doctrine.   \n",
       "12440         2           A Russian who supports Kremlin doctrine.   \n",
       "12441         2           A Russian who supports Kremlin doctrine.   \n",
       "\n",
       "       agree_with_majority_binary      id  encoded_label  \n",
       "0                            True     1-0              1  \n",
       "1                            True     1-1              1  \n",
       "2                           False     1-2              0  \n",
       "4                           False     2-1              1  \n",
       "5                           False     2-2              0  \n",
       "...                           ...     ...            ...  \n",
       "12437                        True  4670-1              1  \n",
       "12438                        True  4670-2              1  \n",
       "12439                        True  4671-0              1  \n",
       "12440                        True  4671-1              1  \n",
       "12441                        True  4671-2              1  \n",
       "\n",
       "[11902 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load original semicolon-separated file\n",
    "df = pd.read_csv(\"HateWiC_IndividualAnnos.csv\", sep=\";\")\n",
    "\n",
    "# Filter out undecidable labels\n",
    "df = df[df['annotation_label'] != 'Cannot decide']\n",
    "\n",
    "# Assign unique IDs per row for annotation-level classification\n",
    "df['id'] = df['annotation_id']\n",
    "\n",
    "# Set binary label column for evaluation\n",
    "df['encoded_label'] = df['binary_label'].astype(int)\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"hatewic_individual_clean.csv\", index=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation_id</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>binary_label</th>\n",
       "      <th>annotator_age</th>\n",
       "      <th>annotator_gender</th>\n",
       "      <th>annotator_ethnicity</th>\n",
       "      <th>annotator_profile_description</th>\n",
       "      <th>example_id</th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>pos</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>wiktionary_definition</th>\n",
       "      <th>agree_with_majority_binary</th>\n",
       "      <th>id</th>\n",
       "      <th>encoded_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-0</td>\n",
       "      <td>annotator_14</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>Reader is 22, Male and Mixed</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>1-0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1-1</td>\n",
       "      <td>annotator_31</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 22, Male and White</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>True</td>\n",
       "      <td>1-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1-2</td>\n",
       "      <td>annotator_47</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "      <td>Female</td>\n",
       "      <td>Other</td>\n",
       "      <td>Reader is 22, Female and Other</td>\n",
       "      <td>1</td>\n",
       "      <td>This is no huge overgrown abbey-lubber.</td>\n",
       "      <td>abbey-lubber</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An able-bodied idler who grew sleek and fat fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>1-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-1</td>\n",
       "      <td>annotator_18</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>Reader is 32, Female and Black</td>\n",
       "      <td>2</td>\n",
       "      <td>They look at those massive tummies and ample a...</td>\n",
       "      <td>Aberzombie</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An unthinking conformist who wears fashions fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>2-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-2</td>\n",
       "      <td>annotator_34</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 35, Female and White</td>\n",
       "      <td>2</td>\n",
       "      <td>They look at those massive tummies and ample a...</td>\n",
       "      <td>Aberzombie</td>\n",
       "      <td>noun</td>\n",
       "      <td>1</td>\n",
       "      <td>An unthinking conformist who wears fashions fr...</td>\n",
       "      <td>False</td>\n",
       "      <td>2-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11897</th>\n",
       "      <td>4670-1</td>\n",
       "      <td>annotator_59</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 24, Female and White</td>\n",
       "      <td>4670</td>\n",
       "      <td>Fuck me, there's actually more ziggers on tele...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4670-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11898</th>\n",
       "      <td>4670-2</td>\n",
       "      <td>annotator_65</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 21, Male and White</td>\n",
       "      <td>4670</td>\n",
       "      <td>Fuck me, there's actually more ziggers on tele...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4670-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11899</th>\n",
       "      <td>4671-0</td>\n",
       "      <td>annotator_8</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 25, Male and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11900</th>\n",
       "      <td>4671-1</td>\n",
       "      <td>annotator_24</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 24, Male and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11901</th>\n",
       "      <td>4671-2</td>\n",
       "      <td>annotator_66</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Reader is 32, Female and White</td>\n",
       "      <td>4671</td>\n",
       "      <td>Why are they dancing?!?!? Don't they know zigg...</td>\n",
       "      <td>zigger</td>\n",
       "      <td>noun</td>\n",
       "      <td>2</td>\n",
       "      <td>A Russian who supports Kremlin doctrine.</td>\n",
       "      <td>True</td>\n",
       "      <td>4671-2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11902 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      annotation_id  annotator_id  annotation_label  binary_label  \\\n",
       "0               1-0  annotator_14  Strongly hateful           1.0   \n",
       "1               1-1  annotator_31    Weakly hateful           1.0   \n",
       "2               1-2  annotator_47       Not hateful           0.0   \n",
       "3               2-1  annotator_18    Weakly hateful           1.0   \n",
       "4               2-2  annotator_34       Not hateful           0.0   \n",
       "...             ...           ...               ...           ...   \n",
       "11897        4670-1  annotator_59    Weakly hateful           1.0   \n",
       "11898        4670-2  annotator_65  Strongly hateful           1.0   \n",
       "11899        4671-0   annotator_8  Strongly hateful           1.0   \n",
       "11900        4671-1  annotator_24    Weakly hateful           1.0   \n",
       "11901        4671-2  annotator_66    Weakly hateful           1.0   \n",
       "\n",
       "       annotator_age annotator_gender annotator_ethnicity  \\\n",
       "0                 22             Male               Mixed   \n",
       "1                 22             Male               White   \n",
       "2                 22           Female               Other   \n",
       "3                 32           Female               Black   \n",
       "4                 35           Female               White   \n",
       "...              ...              ...                 ...   \n",
       "11897             24           Female               White   \n",
       "11898             21             Male               White   \n",
       "11899             25             Male               White   \n",
       "11900             24             Male               White   \n",
       "11901             32           Female               White   \n",
       "\n",
       "        annotator_profile_description  example_id  \\\n",
       "0        Reader is 22, Male and Mixed           1   \n",
       "1        Reader is 22, Male and White           1   \n",
       "2      Reader is 22, Female and Other           1   \n",
       "3      Reader is 32, Female and Black           2   \n",
       "4      Reader is 35, Female and White           2   \n",
       "...                               ...         ...   \n",
       "11897  Reader is 24, Female and White        4670   \n",
       "11898    Reader is 21, Male and White        4670   \n",
       "11899    Reader is 25, Male and White        4671   \n",
       "11900    Reader is 24, Male and White        4671   \n",
       "11901  Reader is 32, Female and White        4671   \n",
       "\n",
       "                                                 example          term   pos  \\\n",
       "0                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "1                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "2                This is no huge overgrown abbey-lubber.  abbey-lubber  noun   \n",
       "3      They look at those massive tummies and ample a...    Aberzombie  noun   \n",
       "4      They look at those massive tummies and ample a...    Aberzombie  noun   \n",
       "...                                                  ...           ...   ...   \n",
       "11897  Fuck me, there's actually more ziggers on tele...        zigger  noun   \n",
       "11898  Fuck me, there's actually more ziggers on tele...        zigger  noun   \n",
       "11899  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "11900  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "11901  Why are they dancing?!?!? Don't they know zigg...        zigger  noun   \n",
       "\n",
       "       sense_id                              wiktionary_definition  \\\n",
       "0             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "1             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "2             1  An able-bodied idler who grew sleek and fat fr...   \n",
       "3             1  An unthinking conformist who wears fashions fr...   \n",
       "4             1  An unthinking conformist who wears fashions fr...   \n",
       "...         ...                                                ...   \n",
       "11897         2           A Russian who supports Kremlin doctrine.   \n",
       "11898         2           A Russian who supports Kremlin doctrine.   \n",
       "11899         2           A Russian who supports Kremlin doctrine.   \n",
       "11900         2           A Russian who supports Kremlin doctrine.   \n",
       "11901         2           A Russian who supports Kremlin doctrine.   \n",
       "\n",
       "       agree_with_majority_binary      id  encoded_label  \n",
       "0                            True     1-0              1  \n",
       "1                            True     1-1              1  \n",
       "2                           False     1-2              0  \n",
       "3                           False     2-1              1  \n",
       "4                           False     2-2              0  \n",
       "...                           ...     ...            ...  \n",
       "11897                        True  4670-1              1  \n",
       "11898                        True  4670-2              1  \n",
       "11899                        True  4671-0              1  \n",
       "11900                        True  4671-1              1  \n",
       "11901                        True  4671-2              1  \n",
       "\n",
       "[11902 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"hatewic_individual_clean.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from difflib import get_close_matches\n",
    "from os import path\n",
    "\n",
    "class ContextEncoder(torch.nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.context_encoder = AutoModel.from_pretrained(encoder_name, output_hidden_states=True)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        context_output = self.context_encoder(input_ids)\n",
    "        return context_output\n",
    "\n",
    "class BiEncoderModel(torch.nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super(BiEncoderModel, self).__init__()\n",
    "        self.context_encoder = ContextEncoder(encoder_name)\n",
    "\n",
    "    def context_forward(self, context_input):\n",
    "        return self.context_encoder.forward(context_input)\n",
    "    \n",
    "\n",
    "def find_target_indices(tknzr, example, term):\n",
    "            \n",
    "    # encode example and target term\n",
    "    example_encoding = tknzr.encode(example, truncation=True)\n",
    "    term_encoding = tknzr.encode(term, add_special_tokens=False)\n",
    "    \n",
    "    # find indices for target term\n",
    "    term_indices = None\n",
    "    for i in range(len(example_encoding)):\n",
    "        if example_encoding[i:i+len(term_encoding)] == term_encoding:\n",
    "            term_indices = (i, i+len(term_encoding))\n",
    "    \n",
    "    if not term_indices:\n",
    "        new_term = None\n",
    "        new_example = None\n",
    "        \n",
    "        # try plural (simple rules)\n",
    "        if term + 's' in example:\n",
    "            new_term = term + 's'\n",
    "        elif term.replace('y', 'ies') in example:\n",
    "            new_term = term.replace('y', 'ies')\n",
    "        elif term.replace('man', 'men') in example:\n",
    "            new_term = term.replace('man', 'men')\n",
    "        else:\n",
    "            # try to find the most similar word in the example\n",
    "            potential_target = get_close_matches(term, example.split(), n=1, cutoff=0.6)\n",
    "            if len(potential_target) == 1:\n",
    "                most_similar = re.sub(r'[^\\w\\s-]','', potential_target[0])\n",
    "                # replace the most similar word (for which we assume misspelling) with the target term\n",
    "                new_example = example.replace(most_similar, term)\n",
    "        \n",
    "        if new_term or new_example:\n",
    "            # encode new term or example\n",
    "            if new_term:\n",
    "                term_encoding = tknzr.encode(new_term, add_special_tokens=False)\n",
    "            elif new_example:\n",
    "                example_encoding = tknzr.encode(new_example, truncation=True)\n",
    "            # try finding indices again\n",
    "            for i in range(len(example_encoding)):\n",
    "                if example_encoding[i:i+len(term_encoding)] == term_encoding:\n",
    "                    term_indices = (i, i+len(term_encoding))\n",
    "    \n",
    "    return term_indices\n",
    "\n",
    "\n",
    "def extract_biencoder_embedding(model, example_encoding, term_indices, layers):\n",
    "\n",
    "    # feed example encodings to the model    \n",
    "    input_ids = torch.tensor([example_encoding])\n",
    "    encoded_layers = model.context_forward(input_ids)[-1]\n",
    "    \n",
    "    # extract selection of hidden layer(s)\n",
    "    if layers == 'last':\n",
    "        layers = -1\n",
    "        vecs = encoded_layers[layers].squeeze(0)\n",
    "    elif layers == 'lastfour':\n",
    "        layers = [-4, -3, -2, -1]\n",
    "        selected_encoded_layers = [encoded_layers[x] for x in layers]\n",
    "        vecs = torch.mean(torch.stack(selected_encoded_layers), 0).squeeze(0)\n",
    "    elif layers == 'all':\n",
    "        vecs = torch.mean(torch.stack(encoded_layers), 0).squeeze(0)\n",
    "    \n",
    "    # target word selection \n",
    "    vecs = vecs.detach()\n",
    "    start_idx, end_idx = term_indices\n",
    "    vecs = vecs[start_idx:end_idx]\n",
    "    \n",
    "    # aggregate sub-word embeddings (by averaging)\n",
    "    vector = torch.mean(vecs, 0)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "def extract_embedding(model, example_encoding, term_indices, layers):\n",
    "\n",
    "    # feed example encodings to the model    \n",
    "    input_ids = torch.tensor([example_encoding])\n",
    "    encoded_layers = model(input_ids)[-1]\n",
    "    \n",
    "    # extract selection of hidden layer(s)\n",
    "    if layers == 'last':\n",
    "        layers = -1\n",
    "        vecs = encoded_layers[layers].squeeze(0)\n",
    "    elif layers == 'lastfour':\n",
    "        layers = [-4, -3, -2, -1]\n",
    "        selected_encoded_layers = [encoded_layers[x] for x in layers]\n",
    "        vecs = torch.mean(torch.stack(selected_encoded_layers), 0).squeeze(0)\n",
    "    elif layers == 'all':\n",
    "        vecs = torch.mean(torch.stack(encoded_layers), 0).squeeze(0)\n",
    "    \n",
    "    # target word selection \n",
    "    vecs = vecs.detach()\n",
    "    start_idx, end_idx = term_indices\n",
    "    vecs = vecs[start_idx:end_idx]\n",
    "    \n",
    "    # aggregate sub-word embeddings (by averaging)\n",
    "    vector = torch.mean(vecs, 0)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "def dataid2biencoderembeddings(input_path, example_column, id_column, output_path, encoder_model_name, wsd_biencoder_path, layers, type='token'):\n",
    "\n",
    "    data = pd.read_csv(input_path)\n",
    "    tknzr = AutoTokenizer.from_pretrained(encoder_model_name)\n",
    "    model = BiEncoderModel(encoder_model_name)\n",
    "    model.load_state_dict(torch.load(wsd_biencoder_path, map_location=torch.device('cpu')), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = dict()\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        example = row[example_column].lower() \n",
    "        example_encoding = tknzr.encode(example, truncation=True)\n",
    "        if type == 'token':\n",
    "            term_indices = find_target_indices(tknzr, example, row['term'].lower())     \n",
    "        elif type == 'sentence':\n",
    "            term_indices = (0, len(example_encoding))\n",
    "        if term_indices:\n",
    "            # extract embedding\n",
    "            vector = extract_biencoder_embedding(model, example_encoding, term_indices, layers=layers)\n",
    "            embeddings[row[id_column]] = vector\n",
    "    \n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def dataid2embeddings(input_path, example_column, id_column, output_path, model_name, layers, type='token'):\n",
    "\n",
    "    data = pd.read_csv(input_path)\n",
    "    tknzr = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = dict()\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        example = row[example_column].lower()\n",
    "        example_encoding = tknzr.encode(example, truncation=True)\n",
    "        if type == 'token':\n",
    "            term_indices = find_target_indices(tknzr, example, row['term'].lower())\n",
    "        elif type == 'sentence':\n",
    "            term_indices = (0, len(example_encoding))\n",
    "        if term_indices:\n",
    "            # extract embedding\n",
    "            vector = extract_embedding(model, example_encoding, term_indices, layers=layers)\n",
    "            embeddings[row[id_column]] = vector\n",
    "    \n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def concatenate_embeddings(embedding_path1, embedding_path2, output_path):\n",
    "    \n",
    "    embeddings = dict()\n",
    "\n",
    "    with open(embedding_path1, 'rb') as infile:\n",
    "        id2embeddings1 = pickle.load(infile)\n",
    "    \n",
    "    with open(embedding_path2, 'rb') as infile:\n",
    "        id2embeddings2 = pickle.load(infile)\n",
    "\n",
    "    for id, e1 in id2embeddings1.items():\n",
    "        e2 = id2embeddings2[id]\n",
    "        embeddings[id] = torch.cat((e1, e2))\n",
    "\n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def get_embedding_file(data_path, id_column, embedding_dir, embedding_type, model, layers):\n",
    "\n",
    "    model_name = model.rsplit('/',1)[1] if '/' in model else model\n",
    "    model_name = model_name.rsplit('.',1)[0] if '.' in model_name else model_name\n",
    "\n",
    "    if 'example' in embedding_type:\n",
    "        embedding_path = embedding_dir + f'{model_name}-{layers}-examples'\n",
    "        if not path.exists(embedding_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'example', id_column, embedding_path, 'bert-base-uncased', model, layers)\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'example', id_column, embedding_path, model, layers, type='token')\n",
    "\n",
    "    if 'generated_definition' in embedding_type:\n",
    "        definition_path = embedding_dir + f'{model_name}-{layers}-generated_definitions'\n",
    "        if not path.exists(definition_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'generated_definition', id_column, definition_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'generated_definition', id_column, definition_path, model, layers, type='sentence')\n",
    "        if not 'example' in embedding_type:\n",
    "            embedding_path = definition_path\n",
    "        else:\n",
    "            combined_path = embedding_path+'-generated_definitions'\n",
    "            if not path.exists(combined_path):\n",
    "                concatenate_embeddings(embedding_path, definition_path, combined_path)\n",
    "            embedding_path = combined_path\n",
    "    elif 'definition' in embedding_type:\n",
    "        definition_path = embedding_dir + f'{model_name}-{layers}-definitions'\n",
    "        if not path.exists(definition_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'definition', id_column, definition_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'definition', id_column, definition_path, model, layers, type='sentence')\n",
    "        if not 'example' in embedding_type:\n",
    "            embedding_path = definition_path\n",
    "        else:\n",
    "            combined_path = embedding_path+'-definitions'\n",
    "            if not path.exists(combined_path):\n",
    "                concatenate_embeddings(embedding_path, definition_path, combined_path)\n",
    "            embedding_path = combined_path\n",
    "    \n",
    "    if 'target' in embedding_type:\n",
    "        target_path = embedding_dir + f'{model_name}-{layers}-targets'\n",
    "        if not path.exists(target_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'profile_description', id_column, target_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'profile_description', id_column, target_path, model, layers, type='sentence')\n",
    "        combined_path = embedding_path+'-targets'\n",
    "        if not path.exists(combined_path):\n",
    "            concatenate_embeddings(embedding_path, target_path, combined_path)\n",
    "        embedding_path = combined_path\n",
    "    \n",
    "    return embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'definition'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'definition'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m embedding_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbeddings saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedding_path)\n",
      "Cell \u001b[1;32mIn[21], line 229\u001b[0m, in \u001b[0;36mget_embedding_file\u001b[1;34m(data_path, id_column, embedding_dir, embedding_type, model, layers)\u001b[0m\n\u001b[0;32m    227\u001b[0m         dataid2biencoderembeddings(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefinition\u001b[39m\u001b[38;5;124m'\u001b[39m, id_column, definition_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, model, layers, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 229\u001b[0m         \u001b[43mdataid2embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefinition\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mid_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefinition_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m embedding_type:\n\u001b[0;32m    231\u001b[0m     embedding_path \u001b[38;5;241m=\u001b[39m definition_path\n",
      "Cell \u001b[1;32mIn[21], line 161\u001b[0m, in \u001b[0;36mdataid2embeddings\u001b[1;34m(input_path, example_column, id_column, output_path, model_name, layers, type)\u001b[0m\n\u001b[0;32m    159\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m tqdm(data\u001b[38;5;241m.\u001b[39miterrows()):\n\u001b[1;32m--> 161\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mexample_column\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m    162\u001b[0m     example_encoding \u001b[38;5;241m=\u001b[39m tknzr\u001b[38;5;241m.\u001b[39mencode(example, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'definition'"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "data_path = \"hatewic_individual_clean.csv\"\n",
    "id_column = \"id\"\n",
    "embedding_dir = \"./embeddings/\"\n",
    "embedding_type = \"example+definition\"\n",
    "model = \"GroNLP/hateBERT\"\n",
    "layers = \"last\"\n",
    "\n",
    "# Generate embeddings\n",
    "embedding_path = get_embedding_file(data_path, id_column, embedding_dir, embedding_type, model, layers)\n",
    "print(\"Embeddings saved to:\", embedding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = \"HateWiC_IndividualAnnos.csv\"\n",
    "output_path = \"hatewic_individual_clean.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep=\";\")\n",
    "df = df.rename(columns={\"annotation_id\": \"id\"})  # required by get_embedding_file\n",
    "df.to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: ./embeddings/hateBERT-last-examples\n"
     ]
    }
   ],
   "source": [
    "# from embeddings import get_embedding_file\n",
    "\n",
    "data_path = \"hatewic_individual_clean.csv\"\n",
    "id_column = \"id\"\n",
    "embedding_dir = \"./embeddings/\"  # make sure this exists\n",
    "embedding_type = \"example\"\n",
    "model = \"GroNLP/hateBERT\"\n",
    "layers = \"last\"\n",
    "\n",
    "embedding_path = get_embedding_file(data_path, id_column, embedding_dir, embedding_type, model, layers)\n",
    "print(\"Embeddings saved to:\", embedding_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, more_itertools, random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from classification import train_test_MLP, MLP_GridSearch, \\\n",
    "#                             train_test_DimProj, DimProj_SimThresSearch\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def tenfoldsplits2instances(instances):\n",
    "    random.shuffle(instances)\n",
    "    tenfolds = [set(fold) for fold in more_itertools.divide(10, instances)]\n",
    "    fold2instances = {i: {'test': tenfolds[i-1],\n",
    "                    'dev': tenfolds[i-2], \n",
    "                    'train': set().union(*[f for j, f in enumerate(tenfolds) if j not in (i-1, 9 if i == 1 else i-2)])\n",
    "                    } for i in range(1, 11)}\n",
    "    return fold2instances\n",
    "\n",
    "\n",
    "def get_split_data(data, id2embeddings, split2items, item_column, id_column):\n",
    "\n",
    "    train_X, train_y, dev_X, dev_y, test_X, test_y = [], [], [], [], [], []\n",
    "    train_data, dev_data, test_data = [], [], []\n",
    "    \n",
    "    for _, row in data.iterrows():\n",
    "        if row[item_column] in split2items['train']:\n",
    "            train_X.append(id2embeddings[row[id_column]])\n",
    "            train_y.append(row['encoded_label'])\n",
    "            train_data.append(row)\n",
    "        elif row[item_column] in split2items['dev']:\n",
    "            dev_X.append(id2embeddings[row[id_column]])\n",
    "            dev_y.append(row['encoded_label'])\n",
    "            dev_data.append(row)\n",
    "        elif row[item_column] in split2items['test']:\n",
    "            test_X.append(id2embeddings[row[id_column]])\n",
    "            test_y.append(row['encoded_label'])\n",
    "            test_data.append(row)\n",
    "\n",
    "    return train_X, train_y, dev_X, dev_y, test_X, test_y,\\\n",
    "          train_data, dev_data, test_data\n",
    "\n",
    "\n",
    "def evaluate(data_path, id_column, label_column, label_encoder, embedding_path, \n",
    "             output_path, clf, params, random_split_seed, splitby):\n",
    "\n",
    "    logs = []\n",
    "    random.seed(random_split_seed)\n",
    "\n",
    "    # load sense representations of model\n",
    "    with open(embedding_path, 'rb') as infile:\n",
    "        id2embeddings = pickle.load(infile)\n",
    "    \n",
    "    # load and shuffle data and encode labels\n",
    "    data = pd.read_csv(data_path).sample(frac=1, random_state=12, ignore_index=True)\n",
    "    #data[label_column] = data[label_column].fillna('NaN') # uncomment if Wiktionary labels\n",
    "    data['encoded_label'] = data[label_column].replace(label_encoder)\n",
    "    # exclude data for which no model representations exist and no label for exist\n",
    "    data = data[data[id_column].isin(id2embeddings)].dropna(subset=['encoded_label']) \n",
    "    data = data.drop(data[data[label_column] == \"None\"].index)\n",
    "    \n",
    "    # initialize 10 folds based on set of unique items\n",
    "    fold2items = tenfoldsplits2instances(list(set(data[splitby])))\n",
    "    tenfold_accuracies, test_data, test_predictions = [], [], []\n",
    "    for i, (fold_no, split2items) in tqdm(enumerate(fold2items.items())):\n",
    "        logs.append(f\"\\nFold {fold_no}\")\n",
    "        \n",
    "        # get data based on sets of items (type specified in splitby)\n",
    "        train_X, train_y, dev_X, dev_y, test_X, test_y,\\\n",
    "          train_fold_data, dev_fold_data, test_fold_data = get_split_data(data, id2embeddings, split2items, splitby, id_column)\n",
    "        logs.append(f\"Train size: {len(train_y)} / Dev size: {len(dev_y)} / Test size: {len(test_y)}\")\n",
    "        test_data.extend([dict(row, **{'test_fold_no': fold_no}) for row in test_fold_data])\n",
    "\n",
    "        # train and test classification model\n",
    "        if clf == 'mlp':\n",
    "            if not params:\n",
    "                best_params = MLP_GridSearch(dev_X, dev_y)\n",
    "                predictions, accuracy = train_test_MLP(train_X, train_y, test_X, test_y, best_params)\n",
    "                logs.append(f\"Grid Search Result - Best Hyperparameters: {best_params}\")\n",
    "            else:\n",
    "                predictions, accuracy = train_test_MLP(train_X, train_y, test_X, test_y, params)\n",
    "        elif clf == 'dimproj':\n",
    "            if not params:\n",
    "                best_params = DimProj_SimThresSearch(train_X, train_y, dev_X, dev_y)\n",
    "                predictions, accuracy = train_test_DimProj(train_fold_data, train_X, train_y, test_X, test_y, best_params) \n",
    "                logs.append(f\"Best Similarity Threshold (for embedding pair selection): {best_params}\")\n",
    "            else:\n",
    "                predictions, accuracy, n_pairs = train_test_DimProj(train_fold_data, train_X, train_y, test_X, test_y, params) \n",
    "                logs.append(f\"{n_pairs} pairs included for dimension creation\")\n",
    "            \n",
    "        logs.append(f\"Accuracy: {accuracy}\")\n",
    "        tenfold_accuracies.append(accuracy)\n",
    "        test_predictions.extend(predictions)\n",
    "    \n",
    "    # save preds\n",
    "    output_df = pd.DataFrame(test_data)\n",
    "    output_df['prediction'] = test_predictions\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "\n",
    "    logs.append(f'\\nAverage of accuracies over {len(tenfold_accuracies)} folds: {sum(tenfold_accuracies)/len(tenfold_accuracies)}')\n",
    "    logs.append(f\"Overall accuracy of predictions for all test folds: {accuracy_score(output_df['encoded_label'], output_df['prediction'])}\")\n",
    "    logs.append(classification_report(output_df['encoded_label'], output_df['prediction'])) \n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting more-itertools\n",
      "  Downloading more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
      "Installing collected packages: more-itertools\n",
      "Successfully installed more-itertools-10.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install more-itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_test_MLP(X_train, y_train, X_test, y_test, params):\n",
    "\n",
    "    X_train = torch.stack(X_train)  \n",
    "    X_test = torch.stack(X_test)\n",
    "\n",
    "    clf = MLPClassifier(random_state=12).set_params(**params).fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return predictions, accuracy\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def MLP_GridSearch(X_dev, y_dev, \n",
    "                   param_grid = {\n",
    "                       'hidden_layer_sizes':[(300, 200, 100, 50), (200, 100, 50), (100, 50)], \n",
    "                       'learning_rate_init':[0.0005, 0.001, 0.005],\n",
    "                       'max_iter': [10, 20, 40, 80, 100, 200]}):\n",
    "\n",
    "    mlp = MLPClassifier(random_state=12)\n",
    "    clf = GridSearchCV(mlp, param_grid)\n",
    "    clf.fit(torch.stack(X_dev), y_dev)\n",
    "\n",
    "    return clf.best_params_\n",
    "\n",
    "\n",
    "def train_test_DimProj(train_data, X_train, y_train, X_test, y_test, params):\n",
    "    # binary classification only\n",
    "\n",
    "    pos_vecs, neg_vecs = [], []\n",
    "    pos_data_ids, neg_data_ids = [], []\n",
    "    for i, y in enumerate(y_train):\n",
    "        if y == 0:\n",
    "            pos_vecs.append(X_train[i])\n",
    "            #pos_data_ids.append(train_data[i]['id'])\n",
    "        else:\n",
    "            neg_vecs.append(X_train[i])\n",
    "            #neg_data_ids.append(train_data[i]['id'])\n",
    "\n",
    "    # create dimension vector\n",
    "    pairwise_dist = pairwise_cosine_similarity(torch.stack(pos_vecs), torch.stack(neg_vecs))\n",
    "    pairwise_dist_dict = dict()\n",
    "    for p_id in range(len(pos_vecs)):\n",
    "        for n_id in range(len(neg_vecs)):\n",
    "            pairwise_dist_dict[(p_id, n_id)] = pairwise_dist[p_id, n_id].item()\n",
    "    top_similar_pairs = [pair for pair, sim in pairwise_dist_dict.items() if sim >= params['sim_thres']]\n",
    "    \n",
    "    if len(top_similar_pairs) > 0:\n",
    "        diff_vecs = [pos_vecs[p_id] - neg_vecs[n_id] for (p_id, n_id) in top_similar_pairs]\n",
    "        dimension = torch.mean(torch.stack(diff_vecs), 0)\n",
    "\n",
    "        #dimension_data = [(pos_data_ids[pos_id], neg_data_ids[neg_id], \n",
    "                #pairwise_dist_dict[(pos_id, neg_id)]) for (pos_id, neg_id) in top_similar_pairs]\n",
    "\n",
    "        # project test embeddings\n",
    "        cos = torch.nn.CosineSimilarity(dim=0)\n",
    "        threshold = 0 # make this decision threshold a parameter?\n",
    "        predictions = []\n",
    "        for x in X_test:\n",
    "            cossim = cos(x, dimension).item()\n",
    "            predictions.append(1 if cossim > threshold else 0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "        return predictions, accuracy, len(top_similar_pairs)\n",
    "    \n",
    "    print(f\"No pairs with similarity above threshold {params['sim_thres']}\")\n",
    "    return [], 0, 0\n",
    "\n",
    "def DimProj_SimThresSearch(X_train, y_train, X_dev, y_dev, \n",
    "                            sim_thresholds=[0.7, 0.75, 0.8, 0.85, 0.9, 0.95]):\n",
    "    \n",
    "    best_acc = 0\n",
    "    for st in sim_thresholds:\n",
    "        params = {'sim_thres': st}\n",
    "        _, acc = train_test_DimProj([], X_train, y_train, X_dev, y_dev, params)\n",
    "        #print('similarity threshold', st, '- accuracy:', acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_params = {'sim_thres': st}\n",
    "    \n",
    "    return best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
      "Requirement already satisfied: packaging>17.1 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torchmetrics) (24.2)\n",
      "Collecting lightning-utilities>=0.8.0\n",
      "  Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torchmetrics) (2.6.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torchmetrics) (2.2.4)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from lightning-utilities>=0.8.0->torchmetrics) (57.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
      "Installing collected packages: lightning-utilities, torchmetrics\n",
      "Successfully installed lightning-utilities-0.14.3 torchmetrics-1.7.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [02:22, 14.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Train size: 9208 / Dev size: 1150 / Test size: 1151\n",
      "Accuracy: 0.741094700260643\n",
      "\n",
      "Fold 2\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7289313640312771\n",
      "\n",
      "Fold 3\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.735881841876629\n",
      "\n",
      "Fold 4\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7419635099913119\n",
      "\n",
      "Fold 5\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.736750651607298\n",
      "\n",
      "Fold 6\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7228496959165943\n",
      "\n",
      "Fold 7\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7471763683753258\n",
      "\n",
      "Fold 8\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7428323197219809\n",
      "\n",
      "Fold 9\n",
      "Train size: 9207 / Dev size: 1151 / Test size: 1151\n",
      "Accuracy: 0.7558644656820156\n",
      "\n",
      "Fold 10\n",
      "Train size: 9208 / Dev size: 1151 / Test size: 1150\n",
      "Accuracy: 0.7208695652173913\n",
      "\n",
      "Average of accuracies over 10 folds: 0.7374214482680468\n",
      "Overall accuracy of predictions for all test folds: 0.7374228864367017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.73      0.74      5921\n",
      "         1.0       0.72      0.75      0.73      5588\n",
      "\n",
      "    accuracy                           0.74     11509\n",
      "   macro avg       0.74      0.74      0.74     11509\n",
      "weighted avg       0.74      0.74      0.74     11509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from tenfold_eval import evaluate\n",
    "\n",
    "label_column = \"binary_label\"\n",
    "label_encoder = {\"0\": 0, \"1\": 1}\n",
    "predictions_path = \"./predictions/hatewic-hatebert-example-last.csv\"\n",
    "clf = \"mlp\"\n",
    "params = {\"hidden_layer_sizes\": (300, 200, 100, 50), \"learning_rate_init\": 0.0005, \"max_iter\": 10}\n",
    "splitby = \"id\"  # other option is \"term\"\n",
    "\n",
    "# logs = evaluate(data_path, id_column, label_column, label_encoder,\n",
    "#                 embedding_path, predictions_path, clf, params, random_split_seed=12, splitby=splitby)\n",
    "\n",
    "logs = evaluate(\n",
    "    data_path=data_path,\n",
    "    id_column=\"id\",\n",
    "    label_column=\"binary_label\",\n",
    "    label_encoder={\"0\": 0, \"1\": 1},\n",
    "    embedding_path=embedding_path,\n",
    "    output_path=predictions_path,\n",
    "    clf=\"mlp\",\n",
    "    params=params,\n",
    "    random_split_seed=12,\n",
    "    splitby=splitby\n",
    ")\n",
    "\n",
    "for log in logs:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(data_path, id_column, label_column, label_encoder,\n",
    "                   embedding_dir, predictions_dir, logs_path,\n",
    "                   models, model_layers, clf, embedding_types,\n",
    "                   splitby, params=dict(), random_split_seed=12):\n",
    "    \n",
    "    logs = []\n",
    "    for model in models:\n",
    "        model_name = model.rsplit('/',1)[1] if '/' in model else model\n",
    "        model_name = model_name.rsplit('.',1)[0] if '.' in model_name else model_name\n",
    "        for embedding_type in embedding_types:\n",
    "            experiment_description = f'\\n{clf} / {model_name} / {embedding_type} embeddings / {model_layers} layer(s) / split by {splitby}\\n'.upper()\n",
    "            logs.append(experiment_description)\n",
    "            logs.append(f\"Hyperparameters: {params}\")\n",
    "            print(experiment_description)\n",
    "            # default embeddings are token embeddings of example usages\n",
    "            embedding_path = get_embedding_file(data_path, id_column, embedding_dir, embedding_type, model, model_layers)\n",
    "            predictions_path = predictions_dir + f'{clf}-{model_name}-{embedding_type}-{model_layers}-splitby{splitby}.csv'\n",
    "            if 'dinu' in data_path:\n",
    "                experiment_logs = dinu_evaluate(data_path, label_column, embedding_path, predictions_path, clf, params, random_split_seed)\n",
    "            else:\n",
    "                experiment_logs = evaluate(data_path, id_column, label_column, label_encoder, embedding_path, \n",
    "                                            predictions_path, clf, params, random_split_seed, splitby) \n",
    "            logs.extend(experiment_logs)\n",
    "            #print(experiment_logs)\n",
    "    \n",
    "    with open(logs_path, 'w') as outfile:\n",
    "        for string in logs:\n",
    "            outfile.write(string+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP / HATEBERT / EXAMPLE EMBEDDINGS / LAST LAYER(S) / SPLIT BY ID\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\archi\\AppData\\Local\\Temp\\ipykernel_12512\\4094459053.py:54: FutureWarning: Series.replace without 'value' and with non-dict-like 'to_replace' is deprecated and will raise in a future version. Explicitly specify the new values instead.\n",
      "  data['encoded_label'] = data[label_column].replace(label_encoder)\n",
      "10it [02:18, 13.89s/it]\n"
     ]
    }
   ],
   "source": [
    "# from run import run\n",
    "\n",
    "# Run evaluation on individual annotations\n",
    "run(\n",
    "    data_path=\"hatewic_individual_clean.csv\",\n",
    "    id_column=\"id\",\n",
    "    label_column=\"binary_label\",  # <- FIXED HERE\n",
    "    label_encoder=None,           # <- None because 0/1 are already fine\n",
    "    embedding_dir=\"./embeddings/\",\n",
    "    predictions_dir=\"./predictions/\",\n",
    "    logs_path=\"hatewic_individual_eval.log\",\n",
    "    models=[\"GroNLP/hateBERT\"],\n",
    "    model_layers=\"last\",\n",
    "    clf=\"mlp\",\n",
    "    embedding_types=[\"example\"],\n",
    "    splitby=\"id\",                 # <- Also use a valid column for splitting\n",
    "    params={\"hidden_layer_sizes\": (300, 200, 100, 50), \"learning_rate_init\": 0.0005, \"max_iter\": 10},\n",
    "    random_split_seed=12\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.73      0.74      5921\n",
      "         1.0       0.72      0.75      0.73      5588\n",
      "\n",
      "    accuracy                           0.74     11509\n",
      "   macro avg       0.74      0.74      0.74     11509\n",
      "weighted avg       0.74      0.74      0.74     11509\n",
      "\n",
      "\n",
      "🔴 False Positives (Not Hateful → Hateful):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>annotator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s my reaction to the violence, however, tha...</td>\n",
       "      <td>pearl-clutcher</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>He was squatting on the ground like a blackfel...</td>\n",
       "      <td>blackfellow</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>But you must not like him because he appointed...</td>\n",
       "      <td>cdesign proponentsist</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Food, real food, not nut cutlets then, and not...</td>\n",
       "      <td>yoghurt-knitter</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[H]is small frame seeming scarecrowed in the o...</td>\n",
       "      <td>scarecrow</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              example                   term  \\\n",
       "1   It’s my reaction to the violence, however, tha...         pearl-clutcher   \n",
       "8   He was squatting on the ground like a blackfel...            blackfellow   \n",
       "15  But you must not like him because he appointed...  cdesign proponentsist   \n",
       "21  Food, real food, not nut cutlets then, and not...        yoghurt-knitter   \n",
       "24  [H]is small frame seeming scarecrowed in the o...              scarecrow   \n",
       "\n",
       "   annotation_label  annotator_id  \n",
       "1       Not hateful  annotator_74  \n",
       "8       Not hateful  annotator_78  \n",
       "15      Not hateful  annotator_58  \n",
       "21      Not hateful  annotator_78  \n",
       "24      Not hateful  annotator_30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 False Negatives (Hateful → Not Hateful):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>annotator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This list has been limited to members and coho...</td>\n",
       "      <td>simp</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>annotator_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>You've got to fire that fuckup.</td>\n",
       "      <td>fuckup</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>annotator_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>According to another superstition, the longer ...</td>\n",
       "      <td>peeler</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why, you would not be boosing till lightman's ...</td>\n",
       "      <td>square</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sealed cells with about to emerge queens are u...</td>\n",
       "      <td>queen</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              example    term  \\\n",
       "2   This list has been limited to members and coho...    simp   \n",
       "10                    You've got to fire that fuckup.  fuckup   \n",
       "13  According to another superstition, the longer ...  peeler   \n",
       "17  Why, you would not be boosing till lightman's ...  square   \n",
       "23  Sealed cells with about to emerge queens are u...   queen   \n",
       "\n",
       "    annotation_label  annotator_id  \n",
       "2   Strongly hateful   annotator_5  \n",
       "10  Strongly hateful  annotator_10  \n",
       "13    Weakly hateful  annotator_79  \n",
       "17    Weakly hateful  annotator_25  \n",
       "23    Weakly hateful  annotator_36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Total Disagreements with Majority: 1745\n",
      "                                                example    term  \\\n",
      "203   They are almost always accompanied by immature...  baldie   \n",
      "8957  Cool, whatever you say, slick, but I need to t...    dick   \n",
      "6464  Speaking of knockout panoramas, if you′re fit ...   tramp   \n",
      "1073  Phototherapy in a 63-year-old man taking SJW  ...     SJW   \n",
      "5487  As far as he knew, I was just a ho-bag who mak...  ho-bag   \n",
      "\n",
      "     annotation_label  annotator_id  \n",
      "203    Weakly hateful  annotator_16  \n",
      "8957      Not hateful  annotator_60  \n",
      "6464   Weakly hateful  annotator_55  \n",
      "1073      Not hateful  annotator_83  \n",
      "5487   Weakly hateful  annotator_83  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load predictions CSV\n",
    "df = pd.read_csv(\"./predictions/mlp-hateBERT-example-last-splitbyid.csv\")\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Not Hateful\", \"Hateful\"],\n",
    "                yticklabels=[\"Not Hateful\", \"Hateful\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plot_confusion_matrix(df['encoded_label'], df['prediction'])\n",
    "\n",
    "# 2. Show classification report\n",
    "print(classification_report(df['encoded_label'], df['prediction']))\n",
    "\n",
    "# 3. False Positives and False Negatives\n",
    "false_pos = df[(df['encoded_label'] == 0) & (df['prediction'] == 1)]\n",
    "false_neg = df[(df['encoded_label'] == 1) & (df['prediction'] == 0)]\n",
    "\n",
    "print(\"\\n🔴 False Positives (Not Hateful → Hateful):\")\n",
    "display(false_pos[['example', 'term', 'annotation_label', 'annotator_id']].head(5))\n",
    "\n",
    "print(\"\\n🔵 False Negatives (Hateful → Not Hateful):\")\n",
    "display(false_neg[['example', 'term', 'annotation_label', 'annotator_id']].head(5))\n",
    "\n",
    "# 4. High disagreement examples (disagreement with majority)\n",
    "disagreements = df[df['agree_with_majority_binary'] == False]\n",
    "\n",
    "print(f\"\\n⚠️ Total Disagreements with Majority: {len(disagreements)}\")\n",
    "print(disagreements[['example', 'term', 'annotation_label', 'annotator_id']].sample(5))\n",
    "\n",
    "# 5. Most frequent error terms\n",
    "error_terms = pd.concat([false_pos, false_neg])\n",
    "term_counts = error_terms['term'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=term_counts.values, y=term_counts.index)\n",
    "plt.title(\"Top 10 Most Error-Prone Terms\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Term\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.73      0.74      5921\n",
      "         1.0       0.72      0.75      0.73      5588\n",
      "\n",
      "    accuracy                           0.74     11509\n",
      "   macro avg       0.74      0.74      0.74     11509\n",
      "weighted avg       0.74      0.74      0.74     11509\n",
      "\n",
      "\n",
      "🔴 False Positives (Not Hateful → Hateful):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>annotator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It’s my reaction to the violence, however, tha...</td>\n",
       "      <td>pearl-clutcher</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>He was squatting on the ground like a blackfel...</td>\n",
       "      <td>blackfellow</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>But you must not like him because he appointed...</td>\n",
       "      <td>cdesign proponentsist</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Food, real food, not nut cutlets then, and not...</td>\n",
       "      <td>yoghurt-knitter</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[H]is small frame seeming scarecrowed in the o...</td>\n",
       "      <td>scarecrow</td>\n",
       "      <td>Not hateful</td>\n",
       "      <td>annotator_30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              example                   term  \\\n",
       "1   It’s my reaction to the violence, however, tha...         pearl-clutcher   \n",
       "8   He was squatting on the ground like a blackfel...            blackfellow   \n",
       "15  But you must not like him because he appointed...  cdesign proponentsist   \n",
       "21  Food, real food, not nut cutlets then, and not...        yoghurt-knitter   \n",
       "24  [H]is small frame seeming scarecrowed in the o...              scarecrow   \n",
       "\n",
       "   annotation_label  annotator_id  \n",
       "1       Not hateful  annotator_74  \n",
       "8       Not hateful  annotator_78  \n",
       "15      Not hateful  annotator_58  \n",
       "21      Not hateful  annotator_78  \n",
       "24      Not hateful  annotator_30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔵 False Negatives (Hateful → Not Hateful):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>term</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>annotator_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This list has been limited to members and coho...</td>\n",
       "      <td>simp</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>annotator_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>You've got to fire that fuckup.</td>\n",
       "      <td>fuckup</td>\n",
       "      <td>Strongly hateful</td>\n",
       "      <td>annotator_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>According to another superstition, the longer ...</td>\n",
       "      <td>peeler</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Why, you would not be boosing till lightman's ...</td>\n",
       "      <td>square</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sealed cells with about to emerge queens are u...</td>\n",
       "      <td>queen</td>\n",
       "      <td>Weakly hateful</td>\n",
       "      <td>annotator_36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              example    term  \\\n",
       "2   This list has been limited to members and coho...    simp   \n",
       "10                    You've got to fire that fuckup.  fuckup   \n",
       "13  According to another superstition, the longer ...  peeler   \n",
       "17  Why, you would not be boosing till lightman's ...  square   \n",
       "23  Sealed cells with about to emerge queens are u...   queen   \n",
       "\n",
       "    annotation_label  annotator_id  \n",
       "2   Strongly hateful   annotator_5  \n",
       "10  Strongly hateful  annotator_10  \n",
       "13    Weakly hateful  annotator_79  \n",
       "17    Weakly hateful  annotator_25  \n",
       "23    Weakly hateful  annotator_36  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ Total Disagreements with Majority: 1745\n",
      "                                                 example         term  \\\n",
      "2121   There were the tawny rocks, like lions couchan...        tawny   \n",
      "1600   I don't want to be a media whore,\" says Babydo...        whore   \n",
      "11505  You brought them home, old trollface, but you ...    trollface   \n",
      "1535   If he is small and weak, he may decide to beco...         punk   \n",
      "724    Also there are the \"Holy Rollers\" and \"Holy Ju...  Holy Roller   \n",
      "\n",
      "      annotation_label  annotator_id  \n",
      "2121    Weakly hateful  annotator_65  \n",
      "1600    Weakly hateful  annotator_66  \n",
      "11505      Not hateful  annotator_65  \n",
      "1535       Not hateful  annotator_58  \n",
      "724        Not hateful  annotator_74  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Load predictions CSV\n",
    "df = pd.read_csv(\"./predictions/hatewic-hatebert-example-last.csv\")\n",
    "\n",
    "# Confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, title='Confusion Matrix'):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=[\"Not Hateful\", \"Hateful\"],\n",
    "                yticklabels=[\"Not Hateful\", \"Hateful\"])\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "plot_confusion_matrix(df['encoded_label'], df['prediction'])\n",
    "\n",
    "# 2. Show classification report\n",
    "print(classification_report(df['encoded_label'], df['prediction']))\n",
    "\n",
    "# 3. False Positives and False Negatives\n",
    "false_pos = df[(df['encoded_label'] == 0) & (df['prediction'] == 1)]\n",
    "false_neg = df[(df['encoded_label'] == 1) & (df['prediction'] == 0)]\n",
    "\n",
    "print(\"\\n🔴 False Positives (Not Hateful → Hateful):\")\n",
    "display(false_pos[['example', 'term', 'annotation_label', 'annotator_id']].head(5))\n",
    "\n",
    "print(\"\\n🔵 False Negatives (Hateful → Not Hateful):\")\n",
    "display(false_neg[['example', 'term', 'annotation_label', 'annotator_id']].head(5))\n",
    "\n",
    "# 4. High disagreement examples (disagreement with majority)\n",
    "disagreements = df[df['agree_with_majority_binary'] == False]\n",
    "\n",
    "print(f\"\\n⚠️ Total Disagreements with Majority: {len(disagreements)}\")\n",
    "print(disagreements[['example', 'term', 'annotation_label', 'annotator_id']].sample(5))\n",
    "\n",
    "# 5. Most frequent error terms\n",
    "error_terms = pd.concat([false_pos, false_neg])\n",
    "term_counts = error_terms['term'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "sns.barplot(x=term_counts.values, y=term_counts.index)\n",
    "plt.title(\"Top 10 Most Error-Prone Terms\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Term\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, pickle, re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "from difflib import get_close_matches\n",
    "from os import path\n",
    "\n",
    "class ContextEncoder(torch.nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super(ContextEncoder, self).__init__()\n",
    "        self.context_encoder = AutoModel.from_pretrained(encoder_name, output_hidden_states=True)\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        context_output = self.context_encoder(input_ids)\n",
    "        return context_output\n",
    "\n",
    "class BiEncoderModel(torch.nn.Module):\n",
    "    def __init__(self, encoder_name):\n",
    "        super(BiEncoderModel, self).__init__()\n",
    "        self.context_encoder = ContextEncoder(encoder_name)\n",
    "\n",
    "    def context_forward(self, context_input):\n",
    "        return self.context_encoder.forward(context_input)\n",
    "    \n",
    "\n",
    "def find_target_indices(tknzr, example, term):\n",
    "            \n",
    "    # encode example and target term\n",
    "    example_encoding = tknzr.encode(example, truncation=True)\n",
    "    term_encoding = tknzr.encode(term, add_special_tokens=False)\n",
    "    \n",
    "    # find indices for target term\n",
    "    term_indices = None\n",
    "    for i in range(len(example_encoding)):\n",
    "        if example_encoding[i:i+len(term_encoding)] == term_encoding:\n",
    "            term_indices = (i, i+len(term_encoding))\n",
    "    \n",
    "    if not term_indices:\n",
    "        new_term = None\n",
    "        new_example = None\n",
    "        \n",
    "        # try plural (simple rules)\n",
    "        if term + 's' in example:\n",
    "            new_term = term + 's'\n",
    "        elif term.replace('y', 'ies') in example:\n",
    "            new_term = term.replace('y', 'ies')\n",
    "        elif term.replace('man', 'men') in example:\n",
    "            new_term = term.replace('man', 'men')\n",
    "        else:\n",
    "            # try to find the most similar word in the example\n",
    "            potential_target = get_close_matches(term, example.split(), n=1, cutoff=0.6)\n",
    "            if len(potential_target) == 1:\n",
    "                most_similar = re.sub(r'[^\\w\\s-]','', potential_target[0])\n",
    "                # replace the most similar word (for which we assume misspelling) with the target term\n",
    "                new_example = example.replace(most_similar, term)\n",
    "        \n",
    "        if new_term or new_example:\n",
    "            # encode new term or example\n",
    "            if new_term:\n",
    "                term_encoding = tknzr.encode(new_term, add_special_tokens=False)\n",
    "            elif new_example:\n",
    "                example_encoding = tknzr.encode(new_example, truncation=True)\n",
    "            # try finding indices again\n",
    "            for i in range(len(example_encoding)):\n",
    "                if example_encoding[i:i+len(term_encoding)] == term_encoding:\n",
    "                    term_indices = (i, i+len(term_encoding))\n",
    "    \n",
    "    return term_indices\n",
    "\n",
    "\n",
    "def extract_biencoder_embedding(model, example_encoding, term_indices, layers):\n",
    "\n",
    "    # feed example encodings to the model    \n",
    "    input_ids = torch.tensor([example_encoding])\n",
    "    encoded_layers = model.context_forward(input_ids)[-1]\n",
    "    \n",
    "    # extract selection of hidden layer(s)\n",
    "    if layers == 'last':\n",
    "        layers = -1\n",
    "        vecs = encoded_layers[layers].squeeze(0)\n",
    "    elif layers == 'lastfour':\n",
    "        layers = [-4, -3, -2, -1]\n",
    "        selected_encoded_layers = [encoded_layers[x] for x in layers]\n",
    "        vecs = torch.mean(torch.stack(selected_encoded_layers), 0).squeeze(0)\n",
    "    elif layers == 'all':\n",
    "        vecs = torch.mean(torch.stack(encoded_layers), 0).squeeze(0)\n",
    "    \n",
    "    # target word selection \n",
    "    vecs = vecs.detach()\n",
    "    start_idx, end_idx = term_indices\n",
    "    vecs = vecs[start_idx:end_idx]\n",
    "    \n",
    "    # aggregate sub-word embeddings (by averaging)\n",
    "    vector = torch.mean(vecs, 0)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "def extract_embedding(model, example_encoding, term_indices, layers):\n",
    "\n",
    "    # feed example encodings to the model    \n",
    "    input_ids = torch.tensor([example_encoding])\n",
    "    encoded_layers = model(input_ids)[-1]\n",
    "    \n",
    "    # extract selection of hidden layer(s)\n",
    "    if layers == 'last':\n",
    "        layers = -1\n",
    "        vecs = encoded_layers[layers].squeeze(0)\n",
    "    elif layers == 'lastfour':\n",
    "        layers = [-4, -3, -2, -1]\n",
    "        selected_encoded_layers = [encoded_layers[x] for x in layers]\n",
    "        vecs = torch.mean(torch.stack(selected_encoded_layers), 0).squeeze(0)\n",
    "    elif layers == 'all':\n",
    "        vecs = torch.mean(torch.stack(encoded_layers), 0).squeeze(0)\n",
    "    \n",
    "    # target word selection \n",
    "    vecs = vecs.detach()\n",
    "    start_idx, end_idx = term_indices\n",
    "    vecs = vecs[start_idx:end_idx]\n",
    "    \n",
    "    # aggregate sub-word embeddings (by averaging)\n",
    "    vector = torch.mean(vecs, 0)\n",
    "    \n",
    "    return vector\n",
    "\n",
    "\n",
    "def dataid2biencoderembeddings(input_path, example_column, id_column, output_path, encoder_model_name, wsd_biencoder_path, layers, type='token'):\n",
    "\n",
    "    data = pd.read_csv(input_path)\n",
    "    tknzr = AutoTokenizer.from_pretrained(encoder_model_name)\n",
    "    model = BiEncoderModel(encoder_model_name)\n",
    "    model.load_state_dict(torch.load(wsd_biencoder_path, map_location=torch.device('cpu')), strict=False)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = dict()\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        example = row[example_column].lower() \n",
    "        example_encoding = tknzr.encode(example, truncation=True)\n",
    "        if type == 'token':\n",
    "            term_indices = find_target_indices(tknzr, example, row['term'].lower())     \n",
    "        elif type == 'sentence':\n",
    "            term_indices = (0, len(example_encoding))\n",
    "        if term_indices:\n",
    "            # extract embedding\n",
    "            vector = extract_biencoder_embedding(model, example_encoding, term_indices, layers=layers)\n",
    "            embeddings[row[id_column]] = vector\n",
    "    \n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def dataid2embeddings(input_path, example_column, id_column, output_path, model_name, layers, type='token'):\n",
    "\n",
    "    data = pd.read_csv(input_path)\n",
    "    tknzr = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "    model.eval()\n",
    "\n",
    "    embeddings = dict()\n",
    "    for _, row in tqdm(data.iterrows()):\n",
    "        example = row[example_column].lower()\n",
    "        example_encoding = tknzr.encode(example, truncation=True)\n",
    "        if type == 'token':\n",
    "            term_indices = find_target_indices(tknzr, example, row['term'].lower())\n",
    "        elif type == 'sentence':\n",
    "            term_indices = (0, len(example_encoding))\n",
    "        if term_indices:\n",
    "            vector = extract_embedding(model, example_encoding, term_indices, layers=layers)\n",
    "            embeddings[row[id_column]] = vector\n",
    "        else:\n",
    "            print(f\"⚠️ Skipping ID {row[id_column]} — term '{row['term']}' not found in example.\")\n",
    "\n",
    "    \n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def concatenate_embeddings(embedding_path1, embedding_path2, output_path):\n",
    "    \n",
    "    embeddings = dict()\n",
    "\n",
    "    with open(embedding_path1, 'rb') as infile:\n",
    "        id2embeddings1 = pickle.load(infile)\n",
    "    \n",
    "    with open(embedding_path2, 'rb') as infile:\n",
    "        id2embeddings2 = pickle.load(infile)\n",
    "\n",
    "    for id, e1 in id2embeddings1.items():\n",
    "        e2 = id2embeddings2[id]\n",
    "        embeddings[id] = torch.cat((e1, e2))\n",
    "\n",
    "    with open(output_path, 'wb') as outfile:\n",
    "        pickle.dump(embeddings, outfile)\n",
    "\n",
    "\n",
    "def get_embedding_file(data_path, id_column, embedding_dir, embedding_type, model, layers):\n",
    "\n",
    "    model_name = model.rsplit('/',1)[1] if '/' in model else model\n",
    "    model_name = model_name.rsplit('.',1)[0] if '.' in model_name else model_name\n",
    "\n",
    "    if 'example' in embedding_type:\n",
    "        embedding_path = embedding_dir + f'{model_name}-{layers}-examples'\n",
    "        if not path.exists(embedding_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'example', id_column, embedding_path, 'bert-base-uncased', model, layers)\n",
    "            else:\n",
    "                # dataid2embeddings(data_path, 'example', id_column, embedding_path, model, layers, type='token')\n",
    "                dataid2embeddings(data_path, 'example', id_column, embedding_path, model, layers, type='sentence')\n",
    "\n",
    "\n",
    "    if 'generated_definition' in embedding_type:\n",
    "        definition_path = embedding_dir + f'{model_name}-{layers}-generated_definitions'\n",
    "        if not path.exists(definition_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'generated_definition', id_column, definition_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'generated_definition', id_column, definition_path, model, layers, type='sentence')\n",
    "        if not 'example' in embedding_type:\n",
    "            embedding_path = definition_path\n",
    "        else:\n",
    "            combined_path = embedding_path+'-generated_definitions'\n",
    "            if not path.exists(combined_path):\n",
    "                concatenate_embeddings(embedding_path, definition_path, combined_path)\n",
    "            embedding_path = combined_path\n",
    "    elif 'definition' in embedding_type:\n",
    "        definition_path = embedding_dir + f'{model_name}-{layers}-definitions'\n",
    "        if not path.exists(definition_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'definition', id_column, definition_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'definition', id_column, definition_path, model, layers, type='sentence')\n",
    "        if not 'example' in embedding_type:\n",
    "            embedding_path = definition_path\n",
    "        else:\n",
    "            combined_path = embedding_path+'-definitions'\n",
    "            if not path.exists(combined_path):\n",
    "                concatenate_embeddings(embedding_path, definition_path, combined_path)\n",
    "            embedding_path = combined_path\n",
    "    \n",
    "    if 'target' in embedding_type:\n",
    "        target_path = embedding_dir + f'{model_name}-{layers}-targets'\n",
    "        if not path.exists(target_path):\n",
    "            if 'biencoder' in model_name:\n",
    "                dataid2biencoderembeddings(data_path, 'profile_description', id_column, target_path, 'bert-base-uncased', model, layers, type='sentence')\n",
    "            else:\n",
    "                dataid2embeddings(data_path, 'profile_description', id_column, target_path, model, layers, type='sentence')\n",
    "        combined_path = embedding_path+'-targets'\n",
    "        if not path.exists(combined_path):\n",
    "            concatenate_embeddings(embedding_path, target_path, combined_path)\n",
    "        embedding_path = combined_path\n",
    "    \n",
    "    return embedding_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils._testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def train_test_MLP(X_train, y_train, X_test, y_test, params):\n",
    "\n",
    "    X_train = torch.stack(X_train)  \n",
    "    X_test = torch.stack(X_test)\n",
    "\n",
    "    clf = MLPClassifier(random_state=12).set_params(**params).fit(X_train, y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    return predictions, accuracy\n",
    "\n",
    "@ignore_warnings(category=ConvergenceWarning)\n",
    "def MLP_GridSearch(X_dev, y_dev, \n",
    "                   param_grid = {\n",
    "                       'hidden_layer_sizes':[(300, 200, 100, 50), (200, 100, 50), (100, 50)], \n",
    "                       'learning_rate_init':[0.0005, 0.001, 0.005],\n",
    "                       'max_iter': [10, 20, 40, 80, 100, 200]}):\n",
    "\n",
    "    mlp = MLPClassifier(random_state=12)\n",
    "    clf = GridSearchCV(mlp, param_grid)\n",
    "    clf.fit(torch.stack(X_dev), y_dev)\n",
    "\n",
    "    return clf.best_params_\n",
    "\n",
    "\n",
    "def train_test_DimProj(train_data, X_train, y_train, X_test, y_test, params):\n",
    "    # binary classification only\n",
    "\n",
    "    pos_vecs, neg_vecs = [], []\n",
    "    pos_data_ids, neg_data_ids = [], []\n",
    "    for i, y in enumerate(y_train):\n",
    "        if y == 0:\n",
    "            pos_vecs.append(X_train[i])\n",
    "            #pos_data_ids.append(train_data[i]['id'])\n",
    "        else:\n",
    "            neg_vecs.append(X_train[i])\n",
    "            #neg_data_ids.append(train_data[i]['id'])\n",
    "\n",
    "    # create dimension vector\n",
    "    pairwise_dist = pairwise_cosine_similarity(torch.stack(pos_vecs), torch.stack(neg_vecs))\n",
    "    pairwise_dist_dict = dict()\n",
    "    for p_id in range(len(pos_vecs)):\n",
    "        for n_id in range(len(neg_vecs)):\n",
    "            pairwise_dist_dict[(p_id, n_id)] = pairwise_dist[p_id, n_id].item()\n",
    "    top_similar_pairs = [pair for pair, sim in pairwise_dist_dict.items() if sim >= params['sim_thres']]\n",
    "    \n",
    "    if len(top_similar_pairs) > 0:\n",
    "        diff_vecs = [pos_vecs[p_id] - neg_vecs[n_id] for (p_id, n_id) in top_similar_pairs]\n",
    "        dimension = torch.mean(torch.stack(diff_vecs), 0)\n",
    "\n",
    "        #dimension_data = [(pos_data_ids[pos_id], neg_data_ids[neg_id], \n",
    "                #pairwise_dist_dict[(pos_id, neg_id)]) for (pos_id, neg_id) in top_similar_pairs]\n",
    "\n",
    "        # project test embeddings\n",
    "        cos = torch.nn.CosineSimilarity(dim=0)\n",
    "        threshold = 0 # make this decision threshold a parameter?\n",
    "        predictions = []\n",
    "        for x in X_test:\n",
    "            cossim = cos(x, dimension).item()\n",
    "            predictions.append(1 if cossim > threshold else 0)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "        return predictions, accuracy, len(top_similar_pairs)\n",
    "    \n",
    "    print(f\"No pairs with similarity above threshold {params['sim_thres']}\")\n",
    "    return [], 0, 0\n",
    "\n",
    "def DimProj_SimThresSearch(X_train, y_train, X_dev, y_dev, \n",
    "                            sim_thresholds=[0.7, 0.75, 0.8, 0.85, 0.9, 0.95]):\n",
    "    \n",
    "    best_acc = 0\n",
    "    for st in sim_thresholds:\n",
    "        params = {'sim_thres': st}\n",
    "        _, acc = train_test_DimProj([], X_train, y_train, X_dev, y_dev, params)\n",
    "        #print('similarity threshold', st, '- accuracy:', acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_params = {'sim_thres': st}\n",
    "    \n",
    "    return best_params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, more_itertools, random\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "# from classification import train_test_MLP, train_test_DimProj\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "def fivefoldsplits2instances(instances):\n",
    "    random.shuffle(instances)\n",
    "    fivefolds = [set(fold) for fold in more_itertools.divide(5, instances)]\n",
    "    fold2instances = {i: {'test': fivefolds[i-2],\n",
    "                    'train': set().union(*[f for j, f in enumerate(fivefolds) if (j) != (4 if i == 1 else i-2)])\n",
    "                    } for i in range(1, 6)}\n",
    "    return fold2instances\n",
    "\n",
    "\n",
    "def get_split_data(data, id2embeddings, split2ids):\n",
    "\n",
    "    train_X, train_y, test_X, test_y = [], [], [], []\n",
    "    train_data, test_data = [], []\n",
    "    for _, row in data.iterrows():\n",
    "        if row['id'] in split2ids['train']:\n",
    "            train_X.append(id2embeddings[row['id']])\n",
    "            train_y.append(row['encoded_label'])\n",
    "            train_data.append(row)\n",
    "        elif row['id'] in split2ids['test']:\n",
    "            test_X.append(id2embeddings[row['id']])\n",
    "            test_y.append(row['encoded_label'])\n",
    "            test_data.append(row)\n",
    "\n",
    "    return train_X, train_y, test_X, test_y,\\\n",
    "          train_data, test_data\n",
    "\n",
    "\n",
    "def dinu_evaluate(data_path, label_column, embedding_path, output_path, clf, params, random_split_seed):\n",
    "\n",
    "    logs = []\n",
    "    random.seed(random_split_seed)\n",
    "\n",
    "    # load sense representations of model\n",
    "    with open(embedding_path, 'rb') as infile:\n",
    "        id2embeddings = pickle.load(infile)\n",
    "    \n",
    "    # load and shuffle data and encode labels\n",
    "    data = pd.read_csv(data_path).sample(frac=1, random_state=12, ignore_index=True) \n",
    "    data['encoded_label'] = data[label_column]\n",
    "    # exclude data for which no model representations exist\n",
    "    data = data[data['id'].isin(id2embeddings)]\n",
    "    \n",
    "    # initialize 5 folds based on ids \n",
    "    fold2ids = fivefoldsplits2instances(list(set(data['id'])))\n",
    "    fivefold_accuracies, test_data, test_predictions = [], [], []\n",
    "    for i, (fold_no, split2ids) in tqdm(enumerate(fold2ids.items())):\n",
    "        assert len(set.intersection(*list(split2ids.values()))) == 0\n",
    "        logs.append(f\"\\nFold {fold_no}\")\n",
    "        \n",
    "        # get data based on sets of ids\n",
    "        train_X, train_y, test_X, test_y,\\\n",
    "          train_fold_data, test_fold_data = get_split_data(data, id2embeddings, split2ids)\n",
    "        logs.append(f\"Train size: {len(train_y)} / Test size: {len(test_y)}\")\n",
    "        test_data.extend([dict(row, **{'test_fold_no': fold_no}) for row in test_fold_data])\n",
    "\n",
    "        # train and test classification model\n",
    "        if clf == 'mlp':\n",
    "            predictions, accuracy = train_test_MLP(train_X, train_y, test_X, test_y, params)\n",
    "        elif clf == 'dimproj':\n",
    "            predictions, accuracy = train_test_DimProj(train_fold_data, train_X, train_y, test_X, test_y, params) \n",
    "            \n",
    "        logs.append(f\"Accuracy: {accuracy}\")\n",
    "        fivefold_accuracies.append(accuracy)\n",
    "        test_predictions.extend(predictions)\n",
    "    \n",
    "    # save preds\n",
    "    output_df = pd.DataFrame(test_data)\n",
    "    output_df['prediction'] = test_predictions\n",
    "    output_df.to_csv(output_path, index=False)\n",
    "\n",
    "    logs.append(f'\\nAverage of accuracies over {len(fivefold_accuracies)} folds: {sum(fivefold_accuracies)/len(fivefold_accuracies)}')\n",
    "    logs.append(f\"Overall accuracy of predictions for all test folds: {accuracy_score(output_df['encoded_label'], output_df['prediction'])}\")\n",
    "    logs.append(classification_report(output_df['encoded_label'], output_df['prediction'])) \n",
    "    logs.append(f\"\\nAccuracy of predictions for each term:\")\n",
    "    term_accuracies = []\n",
    "    for term in set(output_df['term']):\n",
    "        preds = [p for p, t in zip(output_df['prediction'], output_df['term']) if t == term]\n",
    "        gold = [g for g, t in zip(output_df['encoded_label'], output_df['term']) if t == term]\n",
    "        acc = accuracy_score(gold, preds)\n",
    "        term_accuracies.append(acc)\n",
    "        logs.append(f\"{term}: {acc}\")\n",
    "    logs.append(f'\\nAverage of accuracies over {len(term_accuracies)} terms: {sum(term_accuracies)/len(term_accuracies)}')\n",
    "\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved at: ./embeddings/hateBERT-last-examples\n"
     ]
    }
   ],
   "source": [
    "# # from embeddings import get_embedding_file\n",
    "\n",
    "# embedding_path = get_embedding_file(\n",
    "#     data_path=\"dinu1_clean.csv\",\n",
    "#     id_column=\"id\",\n",
    "#     embedding_dir=\"./embeddings/\",\n",
    "#     embedding_type=\"example\",\n",
    "#     model=\"GroNLP/hateBERT\",\n",
    "#     layers=\"last\"\n",
    "# )\n",
    "# print(\"Embeddings saved at:\", embedding_path)\n",
    "\n",
    "\n",
    "embedding_path = get_embedding_file(\n",
    "    data_path=\"dinu1_clean.csv\",\n",
    "    id_column=\"id\",\n",
    "    embedding_dir=\"./embeddings/\",\n",
    "    embedding_type=\"example\",\n",
    "    model=\"GroNLP/hateBERT\",\n",
    "    layers=\"last\"\n",
    ")\n",
    "\n",
    "print(\"Embeddings saved at:\", embedding_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# from dinu_eval import dinu_evaluate\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[43mdinu_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdinu1_clean.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbinary_label\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./predictions/dinu1-hatebert-example.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_layer_sizes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate_init\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0005\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_iter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_split_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\n\u001b[0;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m log \u001b[38;5;129;01min\u001b[39;00m logs:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(log)\n",
      "Cell \u001b[1;32mIn[37], line 64\u001b[0m, in \u001b[0;36mdinu_evaluate\u001b[1;34m(data_path, label_column, embedding_path, output_path, clf, params, random_split_seed)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# train and test classification model\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m clf \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m     predictions, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_MLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m clf \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimproj\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     66\u001b[0m     predictions, accuracy \u001b[38;5;241m=\u001b[39m train_test_DimProj(train_fold_data, train_X, train_y, test_X, test_y, params) \n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\sklearn\\utils\\_testing.py:147\u001b[0m, in \u001b[0;36m_IgnoreWarnings.__call__.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategory)\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[36], line 12\u001b[0m, in \u001b[0;36mtrain_test_MLP\u001b[1;34m(X_train, y_train, X_test, y_test, params)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@ignore_warnings\u001b[39m(category\u001b[38;5;241m=\u001b[39mConvergenceWarning)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_test_MLP\u001b[39m(X_train, y_train, X_test, y_test, params):\n\u001b[1;32m---> 12\u001b[0m     X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m     13\u001b[0m     X_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(X_test)\n\u001b[0;32m     15\u001b[0m     clf \u001b[38;5;241m=\u001b[39m MLPClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\u001b[38;5;241m.\u001b[39mset_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# from dinu_eval import dinu_evaluate\n",
    "\n",
    "logs = dinu_evaluate(\n",
    "    data_path=\"dinu1_clean.csv\",\n",
    "    label_column=\"binary_label\",\n",
    "    embedding_path=embedding_path,\n",
    "    output_path=\"./predictions/dinu1-hatebert-example.csv\",\n",
    "    clf=\"mlp\",\n",
    "    params={\"hidden_layer_sizes\": (300, 200, 100, 50), \"learning_rate_init\": 0.0005, \"max_iter\": 10},\n",
    "    random_split_seed=12\n",
    ")\n",
    "\n",
    "for log in logs:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './embeddings/hateBERT-last-examples.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./embeddings/hateBERT-last-examples.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     id2embeddings \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of embeddings:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(id2embeddings))\n",
      "File \u001b[1;32mc:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './embeddings/hateBERT-last-examples.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"./embeddings/hateBERT-last-examples.pkl\", \"rb\") as f:\n",
    "    id2embeddings = pickle.load(f)\n",
    "\n",
    "print(\"Number of embeddings:\", len(id2embeddings))\n",
    "print(\"Sample keys:\", list(id2embeddings.keys())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1018/1018 [00:58<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings: 1018\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load cleaned DINU1\n",
    "df = pd.read_csv(\"dinu1_clean.csv\")\n",
    "\n",
    "# Load HateBERT model\n",
    "model_name = \"GroNLP/hateBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "model.eval()\n",
    "\n",
    "# Build embeddings dictionary\n",
    "embeddings = {}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        example = row[\"example\"].lower()\n",
    "        input_ids = tokenizer.encode(example, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            last_hidden_state = outputs.hidden_states[-1].squeeze(0)\n",
    "            sentence_vector = torch.mean(last_hidden_state, dim=0)\n",
    "            embeddings[row[\"id\"]] = sentence_vector\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed on ID {row['id']}: {e}\")\n",
    "\n",
    "# Save to file\n",
    "with open(\"hatebert-last-dinu1-fullsentence.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"✅ Saved embeddings:\", len(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:07,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Train size: 815 / Test size: 203\n",
      "Accuracy: 0.7339901477832512\n",
      "\n",
      "Fold 2\n",
      "Train size: 814 / Test size: 204\n",
      "Accuracy: 0.7107843137254902\n",
      "\n",
      "Fold 3\n",
      "Train size: 814 / Test size: 204\n",
      "Accuracy: 0.7009803921568627\n",
      "\n",
      "Fold 4\n",
      "Train size: 814 / Test size: 204\n",
      "Accuracy: 0.6911764705882353\n",
      "\n",
      "Fold 5\n",
      "Train size: 815 / Test size: 203\n",
      "Accuracy: 0.6798029556650246\n",
      "\n",
      "Average of accuracies over 5 folds: 0.7033468559837728\n",
      "Overall accuracy of predictions for all test folds: 0.7033398821218074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.68      0.71       549\n",
      "           1       0.66      0.72      0.69       469\n",
      "\n",
      "    accuracy                           0.70      1018\n",
      "   macro avg       0.70      0.70      0.70      1018\n",
      "weighted avg       0.71      0.70      0.70      1018\n",
      "\n",
      "\n",
      "Accuracy of predictions for each term:\n",
      "cracker: 0.6666666666666666\n",
      "retarded: 0.9375\n",
      "jesus: 0.6666666666666666\n",
      "black: 0.5\n",
      "piece: 1.0\n",
      "bag: 0.7333333333333333\n",
      "flip: 1.0\n",
      "bag bitch: 0.0\n",
      "monkey: 0.71875\n",
      "dog: 1.0\n",
      "redneck: 0.8260869565217391\n",
      "hide: 0.42857142857142855\n",
      "ghetto: 0.5365853658536586\n",
      "gay: 0.71875\n",
      "teabagger: 0.8461538461538461\n",
      "red: 0.782608695652174\n",
      "tom: 0.6666666666666666\n",
      "cry: 0.6666666666666666\n",
      "chick: 0.625\n",
      "pretty: 0.6\n",
      "tranny: 0.7\n",
      "girl: 0.7564102564102564\n",
      "pussy: 0.6627906976744186\n",
      "specialize: 0.4444444444444444\n",
      "uglies: 0.7428571428571429\n",
      "sticks: 0.6\n",
      "trash: 0.7075471698113207\n",
      "hang: 0.625\n",
      "queer: 0.7083333333333334\n",
      "dumb: 0.75\n",
      "joke: 0.5714285714285714\n",
      "\n",
      "Average of accuracies over 31 terms: 0.6835102551197526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from dinu_eval import dinu_evaluate\n",
    "\n",
    "logs = dinu_evaluate(\n",
    "    data_path=\"dinu1_clean.csv\",\n",
    "    label_column=\"binary_label\",\n",
    "    embedding_path=\"hatebert-last-dinu1-fullsentence.pkl\",\n",
    "    output_path=\"predictions/dinu1-hatebert-example.csv\",\n",
    "    clf=\"mlp\",\n",
    "    params={\"hidden_layer_sizes\": (300, 200, 100, 50), \"learning_rate_init\": 0.0005, \"max_iter\": 10},\n",
    "    random_split_seed=12\n",
    ")\n",
    "\n",
    "for log in logs:\n",
    "    print(log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:18<00:00, 17.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved embeddings: 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load cleaned DINU2\n",
    "df = pd.read_csv(\"dinu2_clean.csv\")\n",
    "\n",
    "# Load HateBERT model\n",
    "model_name = \"GroNLP/hateBERT\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name, output_hidden_states=True)\n",
    "model.eval()\n",
    "\n",
    "embeddings = {}\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        example = row[\"example\"].lower()\n",
    "        input_ids = tokenizer.encode(example, truncation=True, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            last_hidden_state = outputs.hidden_states[-1].squeeze(0)\n",
    "            sentence_vector = torch.mean(last_hidden_state, dim=0)\n",
    "            embeddings[row[\"id\"]] = sentence_vector\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed on ID {row['id']}: {e}\")\n",
    "\n",
    "with open(\"hatebert-last-dinu2-fullsentence.pkl\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f)\n",
    "\n",
    "print(\"✅ Saved embeddings:\", len(embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Train size: 251 / Test size: 62\n",
      "Accuracy: 0.7903225806451613\n",
      "\n",
      "Fold 2\n",
      "Train size: 250 / Test size: 63\n",
      "Accuracy: 0.6825396825396826\n",
      "\n",
      "Fold 3\n",
      "Train size: 250 / Test size: 63\n",
      "Accuracy: 0.6984126984126984\n",
      "\n",
      "Fold 4\n",
      "Train size: 250 / Test size: 63\n",
      "Accuracy: 0.7142857142857143\n",
      "\n",
      "Fold 5\n",
      "Train size: 251 / Test size: 62\n",
      "Accuracy: 0.6129032258064516\n",
      "\n",
      "Average of accuracies over 5 folds: 0.6996927803379417\n",
      "Overall accuracy of predictions for all test folds: 0.6996805111821086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       152\n",
      "           1       0.71      0.71      0.71       161\n",
      "\n",
      "    accuracy                           0.70       313\n",
      "   macro avg       0.70      0.70      0.70       313\n",
      "weighted avg       0.70      0.70      0.70       313\n",
      "\n",
      "\n",
      "Accuracy of predictions for each term:\n",
      "cracker: 0.6666666666666666\n",
      "tom: 0.8148148148148148\n",
      "cry: 0.7777777777777778\n",
      "retarded: 0.7241379310344828\n",
      "black: 0.6428571428571429\n",
      "trash: 0.7\n",
      "monkey: 0.6923076923076923\n",
      "redneck: 0.7333333333333333\n",
      "ghetto: 0.5517241379310345\n",
      "teabagger: 0.5\n",
      "girl: 0.9\n",
      "\n",
      "Average of accuracies over 11 terms: 0.7003290451566314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from dinu_eval import dinu_evaluate\n",
    "\n",
    "logs = dinu_evaluate(\n",
    "    data_path=\"dinu2_clean.csv\",\n",
    "    label_column=\"binary_label\",\n",
    "    embedding_path=\"hatebert-last-dinu2-fullsentence.pkl\",\n",
    "    output_path=\"predictions/dinu2-hatebert-example.csv\",\n",
    "    clf=\"mlp\",\n",
    "    params={\"hidden_layer_sizes\": (300, 200, 100, 50), \"learning_rate_init\": 0.0005, \"max_iter\": 10},\n",
    "    random_split_seed=12\n",
    ")\n",
    "\n",
    "for log in logs:\n",
    "    print(log)\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-win_amd64.whl (218 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from matplotlib) (2.2.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\archi\\documents\\uic\\421\\paper-reproducibility\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pyparsing-3.2.3 seaborn-0.13.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\archi\\Documents\\UIC\\421\\paper-reproducibility\\venv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
